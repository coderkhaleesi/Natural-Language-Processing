{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is taken from different sources and is a compilation rather than my original work. Please treat it as a tutorial rather than a novel work as it is meant for that.\n",
    "\n",
    "References:\n",
    "\n",
    "https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Language Classification using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names\\\\Arabic.txt', 'data/names\\\\Chinese.txt', 'data/names\\\\Czech.txt', 'data/names\\\\Dutch.txt', 'data/names\\\\English.txt', 'data/names\\\\French.txt', 'data/names\\\\German.txt', 'data/names\\\\Greek.txt', 'data/names\\\\Irish.txt', 'data/names\\\\Italian.txt', 'data/names\\\\Japanese.txt', 'data/names\\\\Korean.txt', 'data/names\\\\Polish.txt', 'data/names\\\\Portuguese.txt', 'data/names\\\\Russian.txt', 'data/names\\\\Scottish.txt', 'data/names\\\\Spanish.txt', 'data/names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "#The data/names folder contains names in different languages. We want to build a text-classification model using RNNs\n",
    "from __future__ import unicode_literals, print_function, division #needed for compatibility between 3.x and 2.x python versions\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def findFiles(path) : return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell takes all the files above and returns a dictionary of String and a List of Strings like\n",
    "   {language1:[name1L1, name2L1,...], language2:[name1L2 name2L2...], ....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "    c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "    \n",
    "    \n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to make the input into a format our model can understand - i.e. as Tensors. We use one-hot encoding as there are only 26 letters in the alphabet and even after taking into account some extra characters like \",\" commas etc., the data would not be sparse if we use one-hot encdoing (57).\n",
    "\n",
    "For more information - see sparsity in NLP (Google it).\n",
    "If you need a refresher on Tensors in Pytorch, see this: https://pytorch.org/docs/stable/tensors.html\n",
    "Just remember Tensors are like matrices in Math and you should be fine.\n",
    "\n",
    "For how \"Enumerate\" in python works, see https://www.geeksforgeeks.org/enumerate-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(all_letters)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "def letterToIndex(l):\n",
    "    return all_letters.find(l)\n",
    "\n",
    "def tensorFromLetter(l): #<1xn sized tensor\n",
    "    tensor = torch.zeros(1, n)\n",
    "    tensor[0][letterToIndex(l)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensorArray(line): #returns no of letters x 1 x n sized tensor\n",
    "    tensor = torch.zeros(len(line), 1, n)\n",
    "    for index, letter in enumerate(line): \n",
    "        tensor[index][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "        \n",
    "print(tensorFromLetter('J'))\n",
    "\n",
    "print(lineToTensorArray('Jones').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto creating our model. We are using RNNs here. To see how they work, head on to the references mentioned in the article in the starting.\n",
    "Keep in mind, when creating an RNN model, we can either concatenate input and hidden states or add them after multiplying with input to hidden and hidden to hidden weights respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
